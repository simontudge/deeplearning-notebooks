{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to prepare a text file for other notebooks to use, most notably the notebook on LSTMs. Simply give it a url for the file, or the local directory and it will do a few things to make the file easier to work with. [Project Gutenburg](http://www.gutenberg.org/) is a good place to look for free text files. This example uses sheakspeare, but other good ideas might be the bible, or any long single work. You could also get more creative and use source code or a latex file for instance, see [this blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) for inspiration.\n",
    "\n",
    "This is the flow of the notebook:\n",
    "\n",
    "1. Remove very rare characters from the file. We will one hot encode the file on a character basis, so each character is another dimention. If a symbol only appears 5 times in a corpus of several millions of words then it is not worth worrying about.\n",
    "2. Possibly strim the beginning and the end of the file, as many of the Gutenburg files have a preamble which is not part of the book and this may confuse our algorithms.\n",
    "3. Create another version of the file which has only lower case ascii characters, space, full-stop (period) and commas. This is a simplified version of the text which may make things easier (but may also be less intereseting to learn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this assumes that you have a corpus that is in one file and will fit in memory. To attempt something more abitious some modifications will need to be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, requests, re, string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.ascii_lowercase\n",
    "string.whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_file(url, name):\n",
    "    \"\"\"\n",
    "    Gets a text file and saves to disk.\n",
    "    \"\"\"\n",
    "    file_name = os.path.join(BASE_DIR, name + '.txt')\n",
    "    r = requests.get(url)\n",
    "    with open(file_name, 'wt') as f:\n",
    "        f.write(r.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file(name):\n",
    "    \"\"\"\n",
    "    Fetches a file and returns a string.\n",
    "    \"\"\"\n",
    "    file_name = os.path.join(BASE_DIR, name + '.txt')\n",
    "    with open(file_name, 'rt') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip(text, first_line, last_line=None):\n",
    "    \"\"\"\n",
    "    Strips the beginning and the end of the text based\n",
    "    on given first and last lines. They must be unique\n",
    "    and exactly as they are in the text.\n",
    "    \"\"\"\n",
    "    \n",
    "    start = text.find(first_line)\n",
    "    if last_line is not None:\n",
    "        end = text.find(last_line) + len(last_line)\n",
    "        return text[start:end]\n",
    "    else:\n",
    "        return text[start:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_rare_chars(text, cutoff=64):\n",
    "    \"\"\"\n",
    "    Takes a string and removes charachters that are deemed rare.\n",
    "    User may specify this through cutoff.\n",
    "    \"\"\"\n",
    "    counts = Counter(text)\n",
    "    to_remove = \"\".join([c for c in counts if counts[c] < cutoff])\n",
    "    # Not very efficient, but readable, and speed doesn't seem to\n",
    "    # matter too much for the toy examples I'm playing with.\n",
    "    new_text = text\n",
    "    for r in to_remove:\n",
    "        new_text = new_text.replace(r, '')\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simplify_text(text):\n",
    "    \"\"\"\n",
    "    Returns a copy of the text with only lower case ascii, full stop,\n",
    "    comma and space, and removes multiple white space. I.e. if there\n",
    "    is a space more than once it changes that to be only one space.\n",
    "    \"\"\"\n",
    "\n",
    "    new_text = text.lower()\n",
    "    # Change all white space to spaces\n",
    "    for w in string.whitespace:\n",
    "        new_text = new_text.replace(w, ' ')\n",
    "    # And get rid of the other rare chars\n",
    "    allowed_chars = list(string.ascii_lowercase) + [' ', '.', ',']\n",
    "    new_text = \"\".join([c for c in new_text if c in allowed_chars])\n",
    "    # And remove repeated whitespace\n",
    "    new_text = \" \".join(new_text.split())\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_text(text, name):\n",
    "    \"\"\"\n",
    "    Saves the text to file.\n",
    "    \"\"\"\n",
    "    file_name = os.path.join(BASE_DIR, name + '.txt')\n",
    "    print(file_name)\n",
    "    with open(file_name, 'wt') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarise(text):\n",
    "    \"\"\"\n",
    "    Prints a few basic facts about the text.\n",
    "    \"\"\"\n",
    "    total_words = len(text.split())\n",
    "    total_chars = len(text)\n",
    "    unique_chars = len(set(text))\n",
    "    print(\"Words:{} Chars:{} Unique Chars:{}\".format(total_words, total_chars, unique_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings:\n",
    "* BASE_DIR is where you are keeping all your data and must exists. The given is recomended.\n",
    "* name is a base name for refering to this corpus (without extentions etc. such as 'shake' for the\n",
    "works of shakespeare. Extensions and other appendages will be handled for you.\n",
    "* url points to the text file on the web that you want to download, or you may have your own file, in which case you can join to work flow after this step.\n",
    "* Can optionally specify the first and last lines of the expected corpus, which will strip and existing \n",
    "file of title matter etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../data/text\"\n",
    "url = \"http://www.gutenberg.org/files/100/100-0.txt\"\n",
    "name = \"shake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_line = \"From fairest creatures we desire increase\"\n",
    "last_line = \"Means to immure herself and not be seen.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fetch_file(url, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = load_file(name)\n",
    "text = strip(text, first_line, last_line)\n",
    "text = strip_rare_chars(text)\n",
    "save_text(text, 'clean' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summarise(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And make a simplified version of the text as well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_text = simplify_text(text)\n",
    "save_text(simple_text, 'simple' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words:955232 Chars:5147125 Unique Chars:29\n"
     ]
    }
   ],
   "source": [
    "summarise(simple_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that they are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32616\r\n",
      "-rw-r--r--  1 simontudge  staff   5.4M  8 Mar 10:36 cleanshake.txt\r\n",
      "-rw-r--r--  1 simontudge  staff   5.6M  8 Mar 10:36 shake.txt\r\n",
      "-rw-r--r--  1 simontudge  staff   4.9M  8 Mar 10:36 simpleshake.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls -lh ../data/text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
