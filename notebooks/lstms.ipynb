{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Netorks and LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook in which we attempt to learn the structure of a corpus of text on a character by character basis and output some pseudo text of this form. The cononcial example is the complete works of shakespeare, but will work with anything that has a certain consistent style.\n",
    "\n",
    "The notebook [prep_text](.prep_text.ipynb) is used to download and preprocess a suitable text file for use with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters. The number of enrollings is equivalent to how many characters we look back at a time. Thus 10 will be enough to learn the structure of most words, but not sentence and line structure. Around 100 is necessary to begin to learn the actual text structuring of the verses etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_enrollings = 84\n",
    "hidden_units = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into memory. This is simple a single string of text. Then we are going to need to iterate over batches of data. Each training sample is (for example) 10 characters one-hot encoded, and the label is the 11th character (also one hot encoded). The model therefore tries to predict the 11th character based on the proceeding 10. It uses a LSTM to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../data/text\"\n",
    "file = \"cleanshake.txt\"\n",
    "file_name = os.path.join(BASE_DIR, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(file_name, 'rt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first step is a create a mapping from characters to numbers, and for convinience one the other way round. Then we replace our data with a list of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_chars = set(text)\n",
    "total_chars = len(all_chars)\n",
    "char2num = {c:i for i,c in enumerate(all_chars)}\n",
    "num2chars = {char2num[c]:c for c in char2num}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take the data set and create the list of numbers, and split this list into a small number of batches. There are some edge effects here, but these are pretty unimportant as we may split the whole 6 mil + data set into four batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simontudge/anaconda/lib/python3.4/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "all_int = [char2num[t] for t in text]\n",
    "int_data = [all_int[i:i + num_enrollings] for i in range(len(text) - num_enrollings)]\n",
    "int_labels = [all_int[i + num_enrollings] for i in range(len(text) - num_enrollings)]\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(int_data, int_labels, train_size=0.9)\n",
    "# The bigger the enrolling number the more batches you will need.\n",
    "# For enrolling of 10 you don't need to batch at all, for around\n",
    "# 64 8 batches will do fine.\n",
    "batches = 16\n",
    "batch_size = int(np.ceil(len(train_data)/batches))\n",
    "batched_data = [train_data[i*batch_size:(i+1)*batch_size] for i in range(batches)]\n",
    "batched_labels = [train_labels[i*batch_size:(i+1)*batch_size] for i in range(batches)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_data = keras.utils.to_categorical(test_data)\n",
    "# test_labels = keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a function that take the whole of the integer data and returns the training data and test data, but does this in batches. The batches can be quite big, as we are close to being able to do the whole thing in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(n):\n",
    "    data = batched_data[n]\n",
    "    labels = batched_labels[n]\n",
    "    data = keras.utils.to_categorical(data)\n",
    "    labels = keras.utils.to_categorical(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use keras to construct the model. Use a LSTM followed by a dense output layer with softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(input_shape=(num_enrollings, total_chars), units=hidden_units, use_bias=False))\n",
    "model.add(keras.layers.Dense(total_chars, activation='softmax', use_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a three year old mid-range mac this takes about 3 hours to go through all of the data once. Consider optimising the code or renting a GPU unit if you have more ambitious plans, as this is about the limit of what it can handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing batch...\n",
      "Fitting Model\n",
      "Epoch 1/1\n",
      "286080/318932 [=========================>....] - ETA: 1:42 - loss: 2.1696 - acc: 0.3944"
     ]
    }
   ],
   "source": [
    "# For testing only\n",
    "sample_size = 10000\n",
    "for b in range(batches):\n",
    "    print(\"Preparing batch...\")\n",
    "    d, l = get_batch(b)\n",
    "    print(\"Fitting Model\")\n",
    "    model.fit(d, l)\n",
    "    # Test periodically. This slows it down! Just use the final output\n",
    "    # as evaluation for now!\n",
    "#     _, ac = model.evaluate(test_data, test_labels)\n",
    "#     print(\"Accuracy: {}%\".format(ac*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the trained model to generate some pseudo text in the style of shakespear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this two helper functions are of use. Firstly, taking a one hot encoded string and take the most likely string representation of this string, and secondly to one-hot encode a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot2string(onehot, r=0):\n",
    "    \"\"\"\n",
    "    Turn the onehot to a string.\n",
    "    r is a measure of randomness. r=0 means that\n",
    "    we always take the most likely string. r=1 means\n",
    "    that we sample the string, taking the values\n",
    "    as the sample probabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    ran = np.random.random()\n",
    "    if ran > r:\n",
    "        return num2chars[onehot.argmax()]\n",
    "    else:\n",
    "        return num2chars[np.random.choice(list(range(total_chars)), p=onehot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def char2onehot(s):\n",
    "    \"\"\"\n",
    "    Returns the one hot representation of the charachter\n",
    "    \"\"\"\n",
    "    x = np.zeros(total_chars)\n",
    "    x[char2num[s]] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_char(s, r=0):\n",
    "    \"\"\"\n",
    "    Gets the next string by calling the model on the input.\n",
    "    \"\"\"\n",
    "    \n",
    "    onehots = np.array([[char2onehot(c) for c in s]])\n",
    "    out = model.predict(onehots)[0]\n",
    "    return onehot2string(out, r)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = np.random.randint(len(text) - num_enrollings)\n",
    "all_text = list(text[start: start+num_enrollings])\n",
    "print(\"\".join(all_text))\n",
    "output_length = 2000\n",
    "r = 0.1\n",
    "for i in range(output_length):\n",
    "    nc = next_char(all_text[-num_enrollings:], r)\n",
    "    all_text.append(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"\".join(all_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Try using a beam search. Generate the next n (=5) next most likely letters, keep doing this, and get ```5**s``` s= number of steps, do this for a small number of steps, then work out the most likely next 10 letters say, and repeat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
